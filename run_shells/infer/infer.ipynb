{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code is based on Facebook's HDemucs code: https://github.com/facebookresearch/demucs\n",
    "\"\"\"\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import hydra\n",
    "import wandb\n",
    "import torchaudio\n",
    "import IPython.display as ipd\n",
    "\n",
    "\n",
    "cwd = Path().resolve()\n",
    "prj_dir = os.path.dirname(os.path.dirname(os.path.abspath(cwd)))\n",
    "print(f'prj_dir:{prj_dir}')\n",
    "sys.path.append(prj_dir)\n",
    "\n",
    "from src.data.datasets import LrHrSet\n",
    "from src.ddp import distrib\n",
    "from src.evaluate import evaluate\n",
    "from src.models import modelFactory\n",
    "from src.utils import bold\n",
    "from src.wandb_logger import _init_wandb_run\n",
    "from hydra import initialize, compose\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "SERIALIZE_KEY_MODELS = 'models'\n",
    "SERIALIZE_KEY_BEST_STATES = 'best_states'\n",
    "SERIALIZE_KEY_STATE = 'state'\n",
    "\n",
    "\n",
    "initialize('../../conf') # Assume the configuration file is in the current folder\n",
    "args = compose(config_name='main_config')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_model(args):\n",
    "    model_name = args.experiment.model\n",
    "    checkpoint_file = Path(args.checkpoint_file)\n",
    "    model = modelFactory.get_model(args)['generator']\n",
    "    package = torch.load(checkpoint_file, 'cpu')\n",
    "    load_best = args.continue_best\n",
    "    if load_best:\n",
    "        logger.info(bold(f'Loading model {model_name} from best state.'))\n",
    "        model.load_state_dict(\n",
    "            package[SERIALIZE_KEY_BEST_STATES][SERIALIZE_KEY_MODELS]['generator'][SERIALIZE_KEY_STATE])\n",
    "    else:\n",
    "        logger.info(bold(f'Loading model {model_name} from last state.'))\n",
    "        model.load_state_dict(package[SERIALIZE_KEY_MODELS]['generator'][SERIALIZE_KEY_STATE])\n",
    "\n",
    "    return model.cuda()\n",
    "\n",
    "#16kHZ-->24kHZ\n",
    "args.checkpoint_file=\"/mnt/cephfs/hjh/train_record/super_resolution/aero/train_outputs/16-24/aero-nfft=512-hl=256/checkpoint.th\"\n",
    "#4kHZ-->16kHZ\n",
    "# args.checkpoint_file=\"/mnt/cephfs/hjh/train_record/super_resolution/aero/train_outputs/4-16/aero-nfft=512-hl=256/checkpoint.th\"\n",
    "\n",
    "model=_load_model(args)\n",
    "\n",
    "print(\"lond model done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.randn(size=(1, 1, 16000)).float().cuda()\n",
    "\n",
    "#16kHZ\n",
    "file=\"/mnt/cephfs/hjh/train_record/super_resolution/aero/dataset/vctk/rs_wav16k/p314/p314_412.wav\"\n",
    "file=\"/mnt/cephfs/hjh/common_dataset/tts/english/microsoft/wavs_16k/v0/en-US-AshleyNeural_1624587085207.wav\"\n",
    "\n",
    "#4kHZ\n",
    "# file=\"/mnt/cephfs/hjh/train_record/super_resolution/aero/dataset/vctk/rs_wav4k/p347/p347_001.wav\"\n",
    "# file=\"/tmp/tts.wav\"\n",
    "# file=\"/mnt/cephfs/hjh/train_record/super_resolution/aero/dataset/vctk/rs_wav4k/p347/p347_001.wav\"\n",
    "\n",
    "x, sr = torchaudio.load(file) #音频sr=16000\n",
    "print(\"原始音频:\")\n",
    "ipd.display(ipd.Audio(x, rate=sr))\n",
    "x=x.unsqueeze(0).cuda()#[1,1,number]\n",
    "y=model(x)\n",
    "\n",
    "print(\"超分后音频:\")\n",
    "print(y.size())\n",
    "ipd.display(ipd.Audio(y.squeeze().detach().cpu(), rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test inver spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from src.models.spec import spectro, ispectro\n",
    "\n",
    "hop_length = 256\n",
    "nfft = 512\n",
    "scale = 1\n",
    "win_length = 512\n",
    "\n",
    "\n",
    "def spec(x):\n",
    "    if np.mod(x.shape[-1], hop_length):\n",
    "        x = F.pad(x, (0, hop_length - np.mod(x.shape[-1], hop_length)))\n",
    "    hl = hop_length\n",
    "\n",
    "    z = spectro(x, nfft, hl, win_length=win_length)[..., :-1, :]\n",
    "    return z\n",
    "\n",
    "\n",
    "def ispec(z):\n",
    "    hl = int(hop_length * scale)\n",
    "    z = F.pad(z, (0, 0, 0, 1))\n",
    "    x = ispectro(z, hl, win_length=win_length)\n",
    "    return x\n",
    "\n",
    "\n",
    "def move_complex_to_channels_dim(z):\n",
    "    B, C, Fr, T = z.shape\n",
    "    m = torch.view_as_real(z).permute(0, 1, 4, 2, 3)\n",
    "    m = m.reshape(B, C * 2, Fr, T)\n",
    "    return m\n",
    "\n",
    "\n",
    "def convert_to_complex(x):\n",
    "    \"\"\"\n",
    "\n",
    "    :param x: signal of shape [Batch, Channels, 2, Freq, TimeFrames]\n",
    "    :return: complex signal of shape [Batch, Channels, Freq, TimeFrames]\n",
    "    \"\"\"\n",
    "    out = x.permute(0, 1, 3, 4, 2)\n",
    "    out = torch.view_as_complex(out.contiguous())\n",
    "    return out\n",
    "\n",
    "\n",
    "file=\"/mnt/cephfs/hjh/train_record/super_resolution/aero/dataset/vctk/rs_wav16k/p314/p314_412.wav\"\n",
    "x, sr = torchaudio.load(file) #音频sr=16000\n",
    "print(\"原始音频:\")\n",
    "ipd.display(ipd.Audio(x, rate=sr))\n",
    "x=x.unsqueeze(0)\n",
    "\n",
    "length = x.shape[-1]\n",
    "\n",
    "#----------------\n",
    "# 提取伪复数\n",
    "#----------------\n",
    "z = spec(x)\n",
    "x = move_complex_to_channels_dim(z)\n",
    "print(\"伪复数维度:\",x.size())\n",
    "\n",
    "#----------------\n",
    "# 复数反转\n",
    "#----------------\n",
    "x = x.unsqueeze(1)\n",
    "print(\"经过encoder-decoder后:\",x.size())\n",
    "x_spec_complex = convert_to_complex(x)\n",
    "x = ispec(x_spec_complex)\n",
    "x = x[..., :length].squeeze()\n",
    "\n",
    "ipd.display(ipd.Audio(x, rate=sr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
